{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development of a wrapper script for MosaicForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import mosaicforecast as mf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "### segmental duplications and clustered sites\n",
    "\n",
    "Development of `bsm/src/mosaicforecast.py` lead to the following:\n",
    "\n",
    "* The implementation of `MosaicForecast/MuTect2-PoN_filter.py` is so memory inefficient that a typical MuTect2/TNhaplotyper callset saturates even the swap memory.  Therefore this filter was reimplemented using `bcftools` in the `mosaicforecast.segdup_clustered_filter` function (see `bsm/src/mosaicforecast.py`).\n",
    "* since `MosaicForecast/MuTect2-PoN_filter.py` also filters for allele frequency, its replacement lead to `mosaicforecast.AF_filter`\n",
    "\n",
    "### gnomAD filter\n",
    "\n",
    "The goal is to remove calls from `input.vcf.gz` that are represented in gnomAD with $\\mathrm{AF} > 0.001$.  The first implementation based on `bcftools annotate` is very inefficient.  Briefly, the command looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if false; then\n",
    "    gnomADvcf=/projects/shared/gnomAD/gnomad.genomes.r2.1.1.sites.vcf.bgz\n",
    "    bcftools annotate --threads 15 -a $gnomADvcf -c 'INFO/AF' -Oz -o output.vcf.gz input.vcf.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even on a tiny `input.vcf.gz` with $<100$ records the process did not finish overnight.  The following tricks will be tested to speed up the calculation:\n",
    "\n",
    "* remove positions from `$gnomADvcf` that are not contained in `input.vcf.gz`\n",
    "* the `INFO` field contains many many subfields that it might be the factor that slows down `bcftools annotate`; try removing all subfields other than AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 52235,\n",
      "  \"iopub_port\": 57775,\n",
      "  \"stdin_port\": 39603,\n",
      "  \"control_port\": 46149,\n",
      "  \"hb_port\": 39695,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"1af31d47-129ae359cb64d92fb2ab62e8\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-b92726bd-bc08-4728-8c1b-e505aeb6f8a5.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
